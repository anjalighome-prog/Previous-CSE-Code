import java.io.*;
import java.util.*;

public class Classifier {
    private ClassifierNode overallNode;

    // Behavior:
    // - This creates a new Classifier from a file.
    // Exception:
    // - IllegalArgumentException: If there is nothing in the file
    // Return:
    // - None
    // Parameter:
    // - input: Reads from a file to build a Classifier
    public Classifier(Scanner input)
    {
        if(input == null)
        {
            throw new IllegalArgumentException();
        }
        overallNode = makeClassifier(input);
    }

    // Behavior:
    // - This is the method that actually makes the Classifier. Since the items in the file
    //   will be arranged in pre-order (root, left, right), the root is recorded, the traversed
    //   to the left and then to the right.
    // Exception:
    // - None
    // Return:
    // - ClassifierNode: returns to the front root of the binary tree after it been constructed
    // Parameter:
    // - input: Reads from a file to build a Classifier binary tree
    private ClassifierNode makeClassifier(Scanner input)
    {
        String line = input.nextLine();
        if(line == null)
        {
            return null;
        }
        else if(!line.contains("Feature: "))
        {
            return new ClassifierNode(null, null, line, null, null, null);
        }
        line = line.substring("Feature: ".length());
        double threshold = Double.parseDouble(input.nextLine().substring("Threshold: ".length()));
        ClassifierNode temp = new ClassifierNode(line, threshold, null, null, null, null);
        temp.left = makeClassifier(input);
        temp.right = makeClassifier(input);
        return temp;
    }

    // Behavior:
    // - This method saves a Classifier to a file in preorder format. If it is a decision node,
    //   if it written in the word, or feature, on one line and then the threshold on the next 
    //   line. If is a label, or final decision node, then it is written on one line.
    // Exception:
    // - IllegalArgumentException: If the way to print to the file (PrintStream) doesn't exist
    // Return:
    // - None
    // Parameter:
    // - output: A PrintStream, to write to a file, will write Classifier to a file
    public void save(PrintStream output)
    {
        if(output == null)
        {
            throw new IllegalArgumentException();
        }
        save(output, overallNode);
    }

    // Behavior:
    // - This is the method that actually writes the Classifier binary tree into the file.
    //   It first records the root, then it traverses the binary tree to the left and then
    //   to the right.
    //   If it is a decision node,
    //   if it written in the word, or feature, on one line and then the threshold on the next 
    //   line. If is a label, or final decision node, then it is written on one line.
    // Exception:
    // - None
    // Return:
    // - None
    // Parameter:
    // - output: A PrintStream, to write to a file, will write Classifier to a file
    // - current: the current ClassifierNode that is being examined to be printed into the file
    //   per the convention stated above.
    private void save(PrintStream output, ClassifierNode current)
    {
        if(current.left == null || current.right == null)
        {
            output.println(current.label);
        }
        else
        {
            output.println("Feature: " + current.feature);
            output.println("Threshold: " + current.threshold);
            save(output, current.left);
            save(output, current.right);
        }
    }

    // Behavior:
    // - This method takes in a message and classifies it as either "spam" or "ham", which is not
    //   spam.
    // Exception:
    // - IllegalArgumentException: If the message input does not exist
    // Return:
    // - String: The final classification of the message, either spam or ham
    // Parameter:
    // - input: The message in the form of a TextBlock to classify as spam or ham
    public String classify(TextBlock input)
    {
        if(input == null)
        {
            throw new IllegalArgumentException();
        }
        return classify(input, overallNode);
    }

    // Behavior:
    // - This is the actual method that classifies a message as spam or ham. It checks the
    //   probability of the current ClassifierNode's feature being in the input TextBlock.
    //   If the probability is greater than or equal to the ClassifierNode's threshold, traverse
    //   to the right of the binary tree, else to the left. The recursion stops with a
    //   the current ClassifierNode has no left or right node to go to, it is a label node.
    // Exception:
    // - None
    // Return:
    // - String: The final classification of the message, either spam or ham
    // Parameter:
    // - input: The message in the form of a TextBlock to classify as spam or ham
    // - current: The current ClassifierNode to check the probability of the word being in the
    //   input TextBlock and the threshold to compare to before further traversal to the final
    //   judgement
    private String classify(TextBlock input, ClassifierNode current)
    {
        if(current.left == null || current.right == null)
        {
            return current.label;
        }
        else
        {
            double percentage = input.get(current.feature);
            if(percentage >= current.threshold)
            {
                return classify(input, current.right);
            }
            return classify(input, current.left);
        }
    }

    // Behavior:
    // - This method makes a Classifier while training it on a data set. It cycles through the
    //   messages and correct answers and trains the Classifier in place.
    // Exception:
    // - IllegalArgumentException: if the messages and the correct answers don't exist, or
    //   the lists are empty, or the sizes of the list don't match.
    // Return:
    // - None
    // Parameter:
    // - data: list of messages to test the Classifier in the form of TextBlocks
    // - labels: list of right classifications correlating to the messages in data.
    public Classifier(List<TextBlock> data, List<String> labels)
    {
        if((data == null || labels == null) || (data.size() == 0 || labels.size() == 0) || (data.size() != labels.size()))
        {
            throw new IllegalArgumentException();
        }
        for(int index = 0; index < data.size(); index++)
        {
            if(overallNode == null)
            {
                overallNode = new ClassifierNode(null, null, labels.get(index), null, null, data.get(index));
            }
            else
            {
                overallNode = training(data.get(index), labels.get(index), overallNode);
            }
        }
    }

    // Behavior:
    // - This is the actual method that trains the Classifier in place. If takes in the current
    //   message and it's correct answer as well as the head of the subtree. It traverses the tree
    //   in the same way that classify does(comparing the probability of the word to threshold)
    //   until it reaches a label node. Then the label is checked with the right answer. If it is
    //   right do nothing, if wrong, then need to get the word that has the biggest threshold
    //   difference between the message TextBlock that made the label node and the current one
    //   and find the probability of that word in the old TextBlock and the current one. Make a 
    //   new ClassifierNode with that word and the midpoint of those two probabilities. Then
    //   readjust the head of the subtree to include the new correct node 
    // Exception:
    // - None
    // Return:
    // - ClassifierNode: The root of the now "corrected" version of Classifier tree 
    // Parameter:
    // - data: the current TextBlock message to use to traverse the tree
    // - label: The correct answer of the TextBlock message
    // - head: root of the subtree to traverse until the label node
    private ClassifierNode training(TextBlock data, String label, ClassifierNode head)
    {
        if(head.label != null)
        {
            if(!head.label.equals(label))
            {
                String featureToAdd = head.createdBy.findBiggestDifference(data);
                double probOne = head.createdBy.get(featureToAdd);
                double probTwo = data.get(featureToAdd);
                ClassifierNode newAdd = new ClassifierNode(featureToAdd, midpoint(probOne, probTwo), null, null, null, null);
                if(newAdd.threshold >= probTwo)
                {
                    newAdd.right = head;
                    newAdd.left = new ClassifierNode(null, null, label, null, null, data);
                }
                else
                {
                    newAdd.left = head;
                    newAdd.right = new ClassifierNode(null, null, label, null, null, data);
                }
                head = newAdd;
                return head;
            }
        }
        else
        {
            double compare = data.get(head.feature);
            if(compare >= head.threshold)
            {
                head.right = training(data, label, head.right);
            }
            else
            {
                head.left = training(data, label, head.left);
            }
        }
        return head;
    }

    private static class ClassifierNode
    {
        public final String feature;
        public final Double threshold;
        public final String label;
        public ClassifierNode left;
        public ClassifierNode right;
        public final TextBlock createdBy;

        // Behavior:
        // - This method creates a ClassifierNode, the non-null fields determining whether it is
        //   a decision node or a label node
        // Exception:
        // - None
        // Return:
        // - None
        // Parameter:
        // - feature: The word
        // - threshold: the decimal to compare to
        // - label: the classification
        // - left: The left node
        // = right: The right node
        // - createdBy: The TextBlock message that creates the label node
        public ClassifierNode(String feature, Double threshold, String label, ClassifierNode left, ClassifierNode right, TextBlock createdBy)
        {
            this.feature = feature;
            this.threshold = threshold;
            this.label = label;
            this.left = left;
            this.right = right;
            this.createdBy = createdBy;
        }
    }
    ////////////////////////////////////////////////////////////////////
    // PROVIDED METHODS - **DO NOT MODIFY ANYTHING BELOW THIS LINE!** //
    ////////////////////////////////////////////////////////////////////

    // Helper method to calcualte the midpoint of two provided doubles.
    private static double midpoint(double one, double two) {
        return Math.min(one, two) + (Math.abs(one - two) / 2.0);
    }    

    // Behavior: Calculates the accuracy of this model on provided Lists of 
    //           testing 'data' and corresponding 'labels'. The label for a 
    //           datapoint at an index within 'data' should be found at the 
    //           same index within 'labels'.
    // Exceptions: IllegalArgumentException if the number of datapoints doesn't match the number 
    //             of provided labels
    // Returns: a map storing the classification accuracy for each of the encountered labels when
    //          classifying
    // Parameters: data - the list of TextBlock objects to classify. Should be non-null.
    //             labels - the list of expected labels for each TextBlock object. 
    //             Should be non-null.
    public Map<String, Double> calculateAccuracy(List<TextBlock> data, List<String> labels) {
        // Check to make sure the lists have the same size (each datapoint has an expected label)
        if (data.size() != labels.size()) {
            throw new IllegalArgumentException(
                    String.format("Length of provided data [%d] doesn't match provided labels [%d]",
                                  data.size(), labels.size()));
        }
        
        // Create our total and correct maps for average calculation
        Map<String, Integer> labelToTotal = new HashMap<>();
        Map<String, Double> labelToCorrect = new HashMap<>();
        labelToTotal.put("Overall", 0);
        labelToCorrect.put("Overall", 0.0);
        
        for (int i = 0; i < data.size(); i++) {
            String result = classify(data.get(i));
            String label = labels.get(i);

            // Increment totals depending on resultant label
            labelToTotal.put(label, labelToTotal.getOrDefault(label, 0) + 1);
            labelToTotal.put("Overall", labelToTotal.get("Overall") + 1);
            if (result.equals(label)) {
                labelToCorrect.put(result, labelToCorrect.getOrDefault(result, 0.0) + 1);
                labelToCorrect.put("Overall", labelToCorrect.get("Overall") + 1);
            }
        }

        // Turn totals into accuracy percentage
        for (String label : labelToCorrect.keySet()) {
            labelToCorrect.put(label, labelToCorrect.get(label) / labelToTotal.get(label));
        }
        return labelToCorrect;
    }
}
